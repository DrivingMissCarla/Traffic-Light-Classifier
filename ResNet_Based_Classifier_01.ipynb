{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necesary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data from simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_DATA_DIR = os.path.join('data', 'sim')\n",
    "\n",
    "sim_file_paths_green = glob(os.path.join(SIM_DATA_DIR, 'green*', '*.png'))\n",
    "sim_file_paths_yellow = glob(os.path.join(SIM_DATA_DIR, 'yellow*', '*.png'))\n",
    "sim_file_paths_red = glob(os.path.join(SIM_DATA_DIR, 'red*', '*.png'))\n",
    "sim_file_paths_none = glob(os.path.join(SIM_DATA_DIR, 'none*', '*.png'))\n",
    "print('From Simulator - Green: {}, Yellow: {}, Red: {}, None: {}'.format(\n",
    "    len(sim_file_paths_green), len(sim_file_paths_yellow), len(sim_file_paths_red), len(sim_file_paths_none)))\n",
    "\n",
    "\n",
    "img_paths.extend(sim_file_paths_green)\n",
    "labels.extend([[1.0, 0.0, 0.0, 0.0] for i in range(len(sim_file_paths_green))])\n",
    "\n",
    "img_paths.extend(sim_file_paths_yellow)\n",
    "labels.extend([[0.0, 1.0, 0.0, 0.0] for i in range(len(sim_file_paths_yellow))])\n",
    "\n",
    "img_paths.extend(sim_file_paths_red)\n",
    "labels.extend([[0.0, 0.0, 1.0, 0.0] for i in range(len(sim_file_paths_red))])\n",
    "\n",
    "img_paths.extend(sim_file_paths_none)\n",
    "labels.extend([[0.0, 0.0, 0.0, 1.0] for i in range(len(sim_file_paths_none))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data from rosbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROSBAG_DATA_DIR = os.path.join('data', 'rosbag')\n",
    "\n",
    "rosbag_file_paths_green = glob(os.path.join(ROSBAG_DATA_DIR, 'green*', '*.jpg'))\n",
    "rosbag_file_paths_yellow = glob(os.path.join(ROSBAG_DATA_DIR, 'yellow*', '*.jpg'))\n",
    "rosbag_file_paths_red = glob(os.path.join(ROSBAG_DATA_DIR, 'red*', '*.jpg'))\n",
    "rosbag_file_paths_none = glob(os.path.join(ROSBAG_DATA_DIR, 'none*', '*.jpg'))\n",
    "print('From Rosbag - Green: {}, Yellow: {}, Red: {}, None: {}'.format(\n",
    "    len(rosbag_file_paths_green), len(rosbag_file_paths_yellow), len(rosbag_file_paths_red),\n",
    "    len(rosbag_file_paths_none)))\n",
    "\n",
    "\n",
    "img_paths.extend(rosbag_file_paths_green)\n",
    "labels.extend([[1.0, 0.0, 0.0, 0.0] for i in range(len(rosbag_file_paths_green))])\n",
    "\n",
    "img_paths.extend(rosbag_file_paths_yellow)\n",
    "labels.extend([[0.0, 1.0, 0.0, 0.0] for i in range(len(rosbag_file_paths_yellow))])\n",
    "\n",
    "img_paths.extend(rosbag_file_paths_red)\n",
    "labels.extend([[0.0, 0.0, 1.0, 0.0] for i in range(len(rosbag_file_paths_red))])\n",
    "\n",
    "img_paths.extend(rosbag_file_paths_none)\n",
    "labels.extend([[0.0, 0.0, 0.0, 1.0] for i in range(len(rosbag_file_paths_none))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data from Heidelberg set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIDELBERG_DATA_DIR = os.path.join('data', 'heidelberg')\n",
    "HEIDELBERG_TRAIN_YAML_FILE = os.path.join(HEIDELBERG_DATA_DIR, 'train.yaml')\n",
    "\n",
    "dataset_info = []\n",
    "\n",
    "for yaml_path in [HEIDELBERG_TRAIN_YAML_FILE]:\n",
    "\n",
    "    yaml_file = open(yaml_path, 'r')\n",
    "    loaded_yaml = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    dataset_info.extend(yaml.load(loaded_yaml))\n",
    "\n",
    "print('Heidelberg data set loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_green = 0\n",
    "count_yellow = 0\n",
    "count_red = 0\n",
    "count_none = 0\n",
    "\n",
    "for i in range(len(dataset_info)):\n",
    "    img_desc = dataset_info[i]\n",
    "    img_path = os.path.join(HEIDELBERG_DATA_DIR, img_desc['path'])\n",
    "\n",
    "    boxes = img_desc['boxes']\n",
    "\n",
    "    if boxes is None or len(boxes) < 1:\n",
    "        img_paths.append(img_path)\n",
    "        labels.append([0.0, 0.0, 0.0, 1.0])\n",
    "        count_none += 1\n",
    "    else:\n",
    "        t = np.array([0, 0, 0])\n",
    "\n",
    "        for box in boxes:\n",
    "            label = box['label']\n",
    "            if label == 'Green':\n",
    "                t += [1, 0, 0]\n",
    "            elif label == 'Yellow':\n",
    "                t += [0, 1, 0]\n",
    "            elif label == 'Red':\n",
    "                t += [0, 0, 1]\n",
    "\n",
    "        t = t > 0\n",
    "        if np.sum(t) <= 1:\n",
    "            if t[0]:\n",
    "                img_paths.append(img_path)\n",
    "                labels.append([1.0, 0.0, 0.0, 0.0])\n",
    "                count_green += 1\n",
    "            elif t[1]:\n",
    "                img_paths.append(img_path)\n",
    "                labels.append([0.0, 1.0, 0.0, 0.0])\n",
    "                count_yellow += 1\n",
    "            elif t[2]:\n",
    "                img_paths.append(img_path)\n",
    "                labels.append([0.0, 0.0, 1.0, 0.0])\n",
    "                count_red += 1\n",
    "            else:\n",
    "                img_paths.append(img_path)\n",
    "                labels.append([0.0, 0.0, 0.0, 1.0])\n",
    "                count_none += 1\n",
    "\n",
    "print('From Heidelberg set - Green: {}, Yellow: {}, Red: {}, None: {}'.format(\n",
    "    count_green, count_yellow, count_red, count_none))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined training and test (validation) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths, labels = shuffle(img_paths, labels)\n",
    "\n",
    "print('Total - imgs: {}, labels: {}'.format(len(img_paths), len(labels)))\n",
    "\n",
    "\n",
    "img_paths_train, img_paths_test, labels_train, labels_test = train_test_split(img_paths, labels, test_size=0.2)\n",
    "\n",
    "print('Train - imgs: {}, labels: {}'.format(len(img_paths_train), len(labels_train)))\n",
    "print('Test - imgs: {}, labels: {}'.format(len(img_paths_test), len(labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing training/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = (int)(random.random() * len(img_paths))\n",
    "img_path = img_paths[i]\n",
    "print('Image Path: {}'.format(img_path))\n",
    "\n",
    "img = cv2.resize(cv2.imread(img_paths[i]), (224, 224))\n",
    "label = labels[i]\n",
    "\n",
    "print('Image Shape: {}'.format(img.shape))\n",
    "print('Image Label: {}'.format(label))\n",
    "print('Image Class: {}'.format(\n",
    "    'green' if label[0] else ('yellow' if label[1] else ('red' if label[2] else 'none'))))\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic-Light Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CLASSES = 4\n",
    "\n",
    "def classifier():\n",
    "    inputs = Input(shape=(224, 224, 3), name=\"in_input\")\n",
    "    resnet = ResNet50(weights='imagenet', input_tensor=inputs)\n",
    "    x = resnet.output\n",
    "\n",
    "    x = Dropout(0.5, name=\"out_dropout_1\")(x)\n",
    "    x = Dense(100, activation='relu', name=\"out_dense_1\")(x)\n",
    "    x = Dropout(0.5, name=\"out_dropout_2\")(x)\n",
    "    x = Dense(NO_CLASSES, activation='softmax', name=\"out_dense_2\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncoment to remove model and collect garbage\n",
    "#del classifier_model\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = classifier()\n",
    "classifier_model.compile(loss=\"binary_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
    "print(classifier_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sample generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(batch_size, img_paths_sample, labels_sample):\n",
    "    while True:\n",
    "        for batch_i in range(0, len(img_paths_sample), batch_size):\n",
    "            imgs = []\n",
    "            lbs = labels_sample[batch_i:batch_i+batch_size]\n",
    "            for img_path in img_paths_sample[batch_i:batch_i+batch_size]:\n",
    "                imgs.append(cv2.resize(cv2.imread(img_path), (224, 224)))\n",
    "            yield np.array(imgs), np.array(lbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "STEEPS_PER_EPOCH = len(img_paths_train) / BATCH_SIZE\n",
    "TEST_STEEPS_PER_EPOCH = len(img_paths_test) / BATCH_SIZE\n",
    "\n",
    "def train_classifier(epochs):\n",
    "\n",
    "    classifier_model.fit_generator(\n",
    "        generate_sample(BATCH_SIZE, img_paths_train, labels_train),\n",
    "        steps_per_epoch=STEEPS_PER_EPOCH, \n",
    "        epochs=epochs,\n",
    "        validation_data = generate_sample(BATCH_SIZE, img_paths_test, labels_test),\n",
    "        validation_steps = TEST_STEEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = (int)(random.random() * len(img_paths))\n",
    "img_path = img_paths[i]\n",
    "print('Image Path: {}'.format(img_path))\n",
    "\n",
    "img = cv2.resize(cv2.imread(img_paths[i]), (224, 224))\n",
    "label = labels[i]\n",
    "\n",
    "print('Image Shape: {}'.format(img.shape))\n",
    "print('Image Label: {}'.format(label))\n",
    "print('Image Class: {}'.format(\n",
    "    'green' if label[0] else ('yellow' if label[1] else ('red' if label[2] else 'none'))))\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "\n",
    "pred = classifier_model.predict(img.reshape(1,224,224,3))[0]\n",
    "print('Prediction: {}'.format(pred))\n",
    "img_cls = np.argmax(pred)\n",
    "print('Predicted Class: {}'.format(\n",
    "    'green' if img_cls==0 else ('yellow' if img_cls==1 else ('red' if img_cls==2 else 'none'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_MODEL_WEIGHTS_FILE = 'classifier_model_weights.h5'\n",
    "CLASSIFIER_MODEL_YAML_FILE = 'classifier_model.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the weights\n",
    "classifier_model.save_weights(CLASSIFIER_MODEL_WEIGHTS_FILE)\n",
    "\n",
    "# Saving the architecture\n",
    "classifier_model_yaml = classifier_model.to_yaml()\n",
    "with open(CLASSIFIER_MODEL_YAML_FILE, \"w\") as classifier_yaml_file:\n",
    "    classifier_yaml_file.write(classifier_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
